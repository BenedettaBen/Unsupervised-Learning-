{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# import required packages\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform as sf\n",
    "import random as rd\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pre processing, dataset description and visualization",
   "id": "4d34a3c32877f494"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Loading dataset erasing nan columns \n",
    "\n",
    "df = pd.read_csv('Unsupervised Learning 23-24 - Project Dataset.csv', delimiter= ';', header = 0,\n",
    "                 usecols= lambda col: col not in ['Row', 'Unnamed: 22','Unnamed: 23'], decimal= ',')\n",
    "# saving number of samples and attributes\n",
    "[N, M] = df.shape"
   ],
   "id": "cf197a2d4b0bc7ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#computing correlation in the dataset\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr, annot = False)\n",
    "#printing the highest correlation values\n",
    "corr = corr.abs()\n",
    "corr = corr.unstack()\n",
    "corr = corr.sort_values(ascending = False)\n",
    "print(corr[corr < 1].head(10))\n",
    "# save the image in a file\n",
    "plt.savefig('correlation.png')\n",
    "\n"
   ],
   "id": "2802957bc43d8180",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#correlation of only the last five continuous variables, in order to zoom the plot on the most correlated variables\n",
    "corr2 = df.iloc[:,range(16,21)].corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr2, annot = True)\n",
    "plt.savefig('correlation2.png')"
   ],
   "id": "dd56ad90ef176650",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Boxplot of the dataset (only the numerical variables)\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(data = df.iloc[:,[0, 16 , 17, 18, 19, 20]])\n",
    "plt.savefig('boxplot.png')\n"
   ],
   "id": "bb7ed56a271b69c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ed95aa0b5eb448b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# distance matrix with Gower distance\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import gower\n",
    "PM3 = gower.gower_matrix(df)    #gower distance\n",
    "plt.imshow(PM3) #plotting the distance matrix\n",
    "plt.colorbar()"
   ],
   "id": "f680b2e5974d5fa4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "idx = rd.sample(range(7199),30 ) #taking only few samples to have a more intuitive distance matrix\n",
    "PM4 = gower.gower_matrix(df.iloc[idx,:]) \n",
    "plt.imshow(PM4) #plotting the sampled distance matrix\n",
    "plt.colorbar()\n",
    "plt.savefig('gower.png')"
   ],
   "id": "13436c36cbddffa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Multidimensional scaling\n",
    "computationally expensive, it will take a while to run"
   ],
   "id": "825c62886f23adb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Multidimensional scaling with Gower distance to visualize the dataset\n",
    "from sklearn.manifold import MDS\n",
    "embedding = MDS(n_components=2, normalized_stress='auto', dissimilarity='precomputed') #setting the MDS model\n",
    "pairdist2 = pairwise_distances(PM3, metric='precomputed') #pairwise distance with Gower distance (PM3)\n",
    "df_transformed2 = embedding.fit_transform(pairdist2) #fitting the model\n",
    "plt.scatter(df_transformed2[:,0], df_transformed2[:,1]) #plotting the MDS"
   ],
   "id": "1c028c7f68863b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Plot of mds of first two components with seaborn scatterplot\n",
    "sns.scatterplot(x = df_transformed2[:,0], y = df_transformed2[:,1], color='green')\n",
    "plt.title(\"MDS with Gower distance\")    \n",
    "plt.xlabel(\"First component\")\n",
    "plt.ylabel(\"Second component\")\n",
    "#save the image\n",
    "plt.savefig('MDS.png')"
   ],
   "id": "4701403c1a540e9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a558443a21832d19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "this will not be used in the following analysis, it's just to show the 3D MDS. Computationally very expensive",
   "id": "97bd1cf577916f5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MDS in 3D (n_components = 3)\n",
    "embedding_3d = MDS(n_components=3, normalized_stress='auto', dissimilarity='precomputed') #setting the MDS model\n",
    "pairdist3 = pairwise_distances(PM3, metric='precomputed') #pairwise distance with Gower distance (PM3)\n",
    "df_transformed3 = embedding_3d.fit_transform(pairdist3) #fitting the model"
   ],
   "id": "3b4d644e703400a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plotting the 3D MDS\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df_transformed3[:,0], df_transformed3[:,1], df_transformed3[:,2], marker='.', s=10, c='green')\n",
    "plt.title(\"MDS with Gower distance\")\n",
    "plt.xlabel(\"First component\")\n",
    "plt.ylabel(\"Second component\")\n",
    "#add third component label\n",
    "ax.set_zlabel('Third component')\n",
    "plt.savefig('MDS3D.png')\n",
    "plt.show()\n"
   ],
   "id": "767e7195a28be595",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TSNE plot to visualize the dataset\n",
    "from sklearn.manifold import TSNE\n",
    "# define the function to plot TSNE\n",
    "def TSNEPlot(dataset, labels):\n",
    "    dist_matrix = gower.gower_matrix(dataset) #compute Gower distance matrix\n",
    "    tsne = TSNE(n_components=2, verbose=0, perplexity=20, n_iter=300, metric=\"precomputed\", init='random') #setting the TSNE model\n",
    "    tsne_results = tsne.fit_transform(dist_matrix) #fitting the model\n",
    "    # plot the first two components\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.scatterplot(x=tsne_results[:, 0], y=tsne_results[:, 1], color= 'green')\n",
    "    plt.title(\"TSNE\")\n",
    "    plt.xlabel(\"First component\")\n",
    "    plt.ylabel(\"Second component\")\n",
    "    plt.savefig('TSNE.png')\n",
    "    plt.show()"
   ],
   "id": "f479f31d5f1e6f22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plotting the TSNE\n",
    "labels = np.ones(N) #setting all the labels to 1\n",
    "TSNEPlot(df,labels)"
   ],
   "id": "158a7a3f809488b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Anomaly detection",
   "id": "39ff0640a8b53fd3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Isolation Forest",
   "id": "936181018750b07e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "#set seed\n",
    "np.random.seed(42)\n",
    "isoF =IsolationForest(contamination= 'auto') #setting the model  \n",
    "isoF.fit(df)    #fitting the model\n",
    "#saving scores for later \n",
    "isof_scores = isoF.decision_function(df)\n",
    "#print(scores)\n",
    "#sorted_idx = np.argsort(scores) #sorting the scores\n",
    "#print(sorted_idx)\n",
    "#sorted_scores = scores[sorted_idx]\n",
    "#print(sorted_scores)\n",
    "\n",
    "# IsoF outliers' prediction\n",
    "classification = isoF.predict(df)\n",
    "tot_outliers = sum(classification == -1) #counting the outliers\n",
    "print(\"Total outliers: \", tot_outliers)\n",
    "print(\"Percentage of outliers: \", tot_outliers/N)\n",
    "\n"
   ],
   "id": "e33fa13dd95ddc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# visualization of the result with MDS\n",
    "sns.scatterplot(x = df_transformed2[:,0], y = df_transformed2[:,1], hue=classification, palette= ['red', 'green'])\n",
    "plt.legend([\"Inlier\", \"Outlier\"])\n",
    "plt.title(\"Isolation Forest\")\n",
    "plt.savefig('IsolationForest.png')"
   ],
   "id": "efa9a50c0d9ea3c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Local Outlier Factor (LOF)",
   "id": "ece579fab4654977"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LOF algorithm with default settings\n",
    "np.random.seed(42)  #set seed\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "Lof = LocalOutlierFactor(metric='precomputed') #setting the model\n",
    "Lof = Lof.fit(PM3)  #fitting the model\n",
    "labels_lof = Lof.fit_predict(PM3)   #predicting the labels\n",
    "\n",
    "print(\"Number of outliers: \", sum(labels_lof== -1))\n",
    "print(\"Number of inliers: \", sum(labels_lof== 1))\n",
    "print(\"Percentage of outliers: \", sum(labels_lof== -1)/N)"
   ],
   "id": "49e2dbfdf75dc3d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the lof distances\n",
    "lof_distances, _ = Lof.kneighbors(PM3) #retrieve the distances\n",
    "plt.plot(lof_distances)\n",
    "plt.title(\"Lof distances graph\")"
   ],
   "id": "521319c4eecdf646",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# sort the distances\n",
    "sort_dist = np.sort(lof_distances,axis=0, )\n",
    "# plot the sorted distances\n",
    "plt.plot(sort_dist[:,-1],) #from the plot we clearly see two knees, isolation forest algorithm stops on the second knees ( around 200 outliers) while Lof algorithm stops on the first knee if in 'auto'\n",
    "\n",
    "#add vertical and horizontal lines to see the two knees\n",
    "plt.axvline(x=6920, color='k', linestyle='--')\n",
    "plt.axhline(y=sort_dist[6920,-1], color='k', linestyle='--')\n",
    "plt.axvline(x=7200-820, color='k', linestyle='--')\n",
    "plt.axhline(y=sort_dist[7200-820,-1], color='k', linestyle='--')\n",
    "\n",
    "#add a marker in the intersections\n",
    "plt.plot(6920, sort_dist[6920,-1], 'o', color='r')\n",
    "plt.plot(7200-820, sort_dist[7200-820,-1], 'o', color='k')\n",
    "\n",
    "print(\"Total outliers: \",N-6920)\n",
    "print(\"Percentage of outliers: \", (N-6920)/N)\n",
    "plt.title(\"Lof distances graph\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Distances\")\n",
    "plt.savefig('LofDistances.png')\n"
   ],
   "id": "987b5ea487a08317",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scores = Lof.negative_outlier_factor_ #get the scores\n",
    "\n",
    "#plt.plot(scores)\n",
    "sort_scores = np.sort(scores,axis=0 )\n",
    "print(sort_scores[-10:])\n",
    "# verify the distribution of the scores and visualize it with a histogram\n",
    "sort_descend_scores = np.flip(sort_scores,axis=0)\n",
    "plt.hist(sort_scores, bins=50, color='blue')\n",
    "plt.title(\"Histogram of the scores\")\n",
    "plt.xlim(-9,9)"
   ],
   "id": "55ebe65da45070a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MDS plot of the LOF result\n",
    "sns.scatterplot(x = df_transformed2[:,0], y = df_transformed2[:,1], hue= labels_lof, palette= ['black', 'yellow'])\n",
    "plt.legend([ \"Outlier\",\"not Outlier\"])\n",
    "plt.title(\"Local Outlier Factor\")"
   ],
   "id": "5a9269a92d66c0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# repeating LOF with isolation forest contamination\n",
    "np.random.seed(42)\n",
    "Lof2 = LocalOutlierFactor(metric='precomputed', contamination= 0.038)  #setting the model with the new contamination\n",
    "Lof2 = Lof2.fit(PM3)    #fitting the model\n",
    "labels_lof2 = Lof2.fit_predict(PM3)  #predicting the labels\n",
    "\n",
    "print(\"Number of outliers: \", sum(labels_lof2== -1))\n",
    "print(\"Number of inliers: \", sum(labels_lof2== 1))"
   ],
   "id": "658ea807d352df24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MDS plot of the LOF result with the new contamination\n",
    "sns.scatterplot(x = df_transformed2[:,0], y = df_transformed2[:,1], hue= labels_lof2, palette= ['red', 'green'])\n",
    "plt.legend([ \"Inlier\",\"Outlier\"])\n",
    "plt.title(\"Local Outlier Factor\")\n",
    "plt.savefig('LOF.png')\n"
   ],
   "id": "1a5e2eb841ca7175",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DBSCAN",
   "id": "9a17fc96e13249dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n"
   ],
   "id": "439714cfd0183054",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from kneed import KneeLocator\n",
    "# set seed\n",
    "np.random.seed(42)\n",
    "# Finding eps and min_samples that maximize silhouette score\n",
    "sil = []\n",
    "knee_y_list = []\n",
    "for i in range(2,20):\n",
    "    nbrs = NearestNeighbors(n_neighbors=i+1, metric= 'precomputed').fit(PM3) # fit the NN model        \n",
    "    distances, indexes = nbrs.kneighbors(PM3)   # retrieve the distances and the indexes   \n",
    "    sorted_distances = np.sort(distances[:,-1], axis=0) # sort the distances\n",
    "    x = np.arange(len(sorted_distances))\n",
    "    knee = KneeLocator(x, sorted_distances, S=1, curve='convex', direction='increasing', interp_method='polynomial')  # find the knee of the sorted distances  \n",
    "    knee_x = knee.knee\n",
    "    knee_y = knee.knee_y\n",
    "    knee_y_list.append(knee_y)\n",
    "    dbscan = DBSCAN(eps=knee_y, min_samples=i , metric='precomputed').fit(PM3) # apply DBSCAN with the knee distance and the number of neighbors\n",
    "    dbscan_labels = dbscan.labels_ # retrieve the labels\n",
    "    # setting all the inliers with label = 1 and all the outliers with label = -1\n",
    "    for j in range(N):\n",
    "        if dbscan_labels[j] == -1:\n",
    "            dbscan_labels[j] = -1\n",
    "        else: dbscan_labels[j] = 1\n",
    "    sil.append(silhouette_score(PM3, dbscan_labels, metric='precomputed') )  # compute the silhouette score\n",
    "    \n",
    "plt.plot(range(2,20),sil, 'o--', color='r') # plot the silhouette score\n",
    "#plt.plot(range(2,20),knee_y_list, 'o--', color='b') # plot the knee\n"
   ],
   "id": "846c5912cc523381",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Epsilon: \" ,knee_y_list[8]) # retrieve the epsilon that maximize the silhouette score\n",
    "print(\"min_samples: \", 10) # retrieve the min_samples that maximize the silhouette score\n",
    "plt.plot(range(2,20),sil, 'o--', color='r') # plot the silhouette score\n",
    "plt.xlabel(\"Number of min_samples\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.title(\"Silhouette score for DBSCAN\")\n",
    "plt.savefig('DBSCAN-SIL.png')\n"
   ],
   "id": "aaab73a1bd543725",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the NN sorted distances with the chosen parameters\n",
    "nbrs = NearestNeighbors(n_neighbors=11, metric= 'precomputed').fit(PM3)\n",
    "distances, indexes = nbrs.kneighbors(PM3) # retrieve the distances and the indexes\n",
    "sorted_distances = np.sort(distances[:,-1], axis=0) # sort the distances\n",
    "plt.plot(sorted_distances) # plot the sorted distances\n",
    "plt.axvline(x=6830, color='k', linestyle='--')\n",
    "plt.axhline(y=sorted_distances[6830], color='k', linestyle='--')\n",
    "print(sorted_distances[6830])\n",
    "plt.title(\"DBSCAN distances graph\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Distances\")\n",
    "plt.savefig('DBSCAN-knee.png')\n"
   ],
   "id": "7314321c440cf3c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DBSCAN with the chosen parameters\n",
    "np.random.seed(42)\n",
    "nbrs = NearestNeighbors(n_neighbors=11, metric= 'precomputed').fit(PM3) # fit the NN model\n",
    "dbscan = DBSCAN(eps=0.028174572, min_samples=10 , metric='precomputed').fit(PM3) # apply DBSCAN with eps corresponding to 3.8% of outliers \n",
    "\n",
    "# Retrieve the labels\n",
    "dbscan_labels = dbscan.labels_\n",
    "#how many clusters\n",
    "print(\"Number of clusters: \", len(set(dbscan_labels)))\n",
    "#setting all the inliers with label = 1 and all the outliers with label = -1\n",
    "for i in range(N):\n",
    "  #print(i)\n",
    "  if dbscan_labels[i] == -1:\n",
    "    dbscan_labels[i] = -1\n",
    "  else: dbscan_labels[i] = 1\n",
    "#print(dbscan_labels)\n",
    "print(\"Number of outliers: \", sum(dbscan_labels== -1))\n",
    "print(\"Number of inliers: \", sum(dbscan_labels== 1))\n",
    "print(\"Percentage of outliers: \", sum(dbscan_labels== -1)/N)\n",
    "print(\"Silhouette: \", silhouette_score(PM3, dbscan_labels, metric='precomputed') )"
   ],
   "id": "110fe3f84aea41f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MDS plot of the DBSCAN result\n",
    "sns.scatterplot(x = df_transformed2[:,0], y = df_transformed2[:,1], hue= dbscan_labels, palette= ['red', 'green'])\n",
    "plt.legend([ \"not Outlier\",\"Outlier\"])\n",
    "plt.title(\"DBSCAN\")\n",
    "plt.savefig('DBSCAN.png')"
   ],
   "id": "6691878275efb6ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reconstruction method: PCA",
   "id": "24546de1374a984d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "NCOMP = 15  # number of components\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=NCOMP)\n",
    "pca_result = pca.fit_transform(PM3) #fitting the model on the distance matrix\n",
    "print('PCA: explained variation per principal component: {}'.format(pca.explained_variance_ratio_.round(3)))\n",
    "print('Total explained variation: ', pca.explained_variance_ratio_.sum())\n",
    "PM_reconstructed = pca.inverse_transform(pca_result) #reconstructing the distance matrix\n",
    "RE_mean = np.mean(np.square(PM_reconstructed-PM3)) #computing the mean squared reconstruction error\n",
    "RE = np.abs(PM_reconstructed-PM3) #computing the absolute reconstruction error\n",
    "print(RE.shape)\n",
    "#print(RE)\n",
    "print('Reconstructed error: %.8f' % RE_mean)\n",
    "RE = np.mean(RE, axis=1)  #computing the mean reconstruction error for each sample\n",
    "plt.plot(RE)"
   ],
   "id": "3be26bb4b033fc16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RE_sorted = np.sort(RE) #sorting the reconstruction errors\n",
    "plt.plot(RE_sorted) #plotting the sorted reconstruction errors"
   ],
   "id": "11410920dca24164",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Chi-squared method for detecting outliers\n",
    "from scipy.stats import chi2\n",
    "\n",
    "alpha = 0.05 # significance value\n",
    "sq_proj = []\n",
    "for i in range(NCOMP):\n",
    "  sq_proj.append((pca_result[:,i]**2)/(np.sqrt(pca.explained_variance_[i]))) #computing the squared projection normalized by the eigenvalues\n",
    "  \n",
    "print(sq_proj[0].shape) #checking the shape of the first element\n",
    "\n",
    "summed_proj = np.sum(sq_proj, axis=0) #summing the squared projections\n",
    "print(summed_proj.shape)\n",
    "tresh = chi2.ppf(1- alpha, NCOMP) #computing the threshold\n",
    "print(tresh)\n",
    "\n",
    "\n",
    "CHI_labels = np.ones(N)\n",
    "CHI_labels[summed_proj > tresh] = -1 # if the sum of the squared projections is greater than the threshold, the sample is an outlier\n",
    "print(\"number of outliers: \", sum(CHI_labels == -1))\n",
    "print(\"number of inliers: \", sum(CHI_labels == 1))\n",
    "print(\"percentage of outliers: \", sum(CHI_labels == -1)/N)"
   ],
   "id": "ddb80fd110e8c3b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MDS plot of the PCA result\n",
    "sns.scatterplot(x = df_transformed2[:,0], y = df_transformed2[:,1], hue= CHI_labels, palette= ['red', 'green'])\n",
    "plt.legend([ \"not Outlier\",\"Outlier\"])\n",
    "plt.title(\"PCA\")\n",
    "plt.savefig('PCA3.png')"
   ],
   "id": "fb082c35e8bc9902",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's compute the rand index of the various methods",
   "id": "cde933b338588822"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.cluster import rand_score\n",
    "\n",
    "# retrieve the labels of the methods\n",
    "ISOF_labels = classification\n",
    "LOF_labels = labels_lof2\n",
    "DBSCAN_labels = dbscan_labels\n",
    "CHI_labels\n",
    "\n",
    "# compute the rand index between the methods\n",
    "\n",
    "rand_index1 = rand_score(ISOF_labels, LOF_labels) #rand index between ISOF and LOF\n",
    "print(\"Rand score between ISOF and LOF \",rand_index1.round(3))\n",
    "\n",
    "rand_index2 = rand_score(LOF_labels, DBSCAN_labels) #rand index between LOF and DBSCAN\n",
    "print(\"Rand score between DBSCAN and LOF \",rand_index2.round(3))\n",
    "\n",
    "rand_index3 = rand_score(LOF_labels, CHI_labels)  #rand index between LOF and PCA\n",
    "print(\"Rand score between PCA and LOF \",rand_index3.round(3))\n",
    "\n",
    "rand_index4 = rand_score(ISOF_labels, DBSCAN_labels)   #rand index between ISOF and DBSCAN\n",
    "print(\"Rand score between ISOF and DBSCAN \",rand_index4.round(3))\n",
    "\n",
    "rand_index5 = rand_score(ISOF_labels, CHI_labels)   #rand index between ISOF and PCA\n",
    "print(\"Rand score between ISOF and PCA \",rand_index5.round(3))\n",
    "\n",
    "rand_index6 = rand_score(CHI_labels, DBSCAN_labels)   #rand index between PCA and DBSCAN\n",
    "print(\"Rand score between PCA and DBSCAN \",rand_index6.round(3))"
   ],
   "id": "6d19fa657ea69bdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Find out which observation are not outlier according to all algorithms\n",
    "total_labels = ISOF_labels + LOF_labels + DBSCAN_labels + CHI_labels #summing the labels \n",
    "#visualize on the MDS plot\n",
    "PAL = ['red', 'blue', 'black', 'orange', 'green']\n",
    "print(\"2 algorithms flagged as outliers, 2 as inliers\" ,sum(total_labels == 0))\n",
    "print(\"3 algorithms flagged as outliers, 1 as inliers\" ,sum(total_labels == -2))\n",
    "print(\"1 algorithms flagged as outliers, 3 as inliers\" ,sum(total_labels == 2))\n",
    "print(\"4 algorithms flagged as outliers\" ,sum(total_labels == -4))\n",
    "print(\"4 algorithms flagged as inliers\" ,sum(total_labels == 4))"
   ],
   "id": "4d1376c8795570a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plotting the classification according to all algorithms\n",
    "fig = sns.scatterplot(x = df_transformed2[:,0], y = df_transformed2[:,1], hue= total_labels, palette= PAL)\n",
    "\n",
    "plt.legend([\"Outlier\", \"3 Outlier 1 Inlier\",\"2 Outlier 2 Inlier\",\"1 Outlier 3 Inlier\" ,\"Inlier\"])\n",
    "plt.title(\"Classification according to all algorithms\")\n",
    "plt.savefig('Classification.png')"
   ],
   "id": "fe3c0b2e3d70c42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "the legend colors are wrong because of seaborn scatterplot, they were corrected manually by us",
   "id": "83945b1b7338562f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Selecting ISOF for the outliers scores\n",
    "plt.plot(isof_scores) #plotting the isof scores\n",
    "#sorted isof scores\n",
    "sorted_isof = np.sort(isof_scores)\n",
    "print(\" min:   \",min(isof_scores))\n",
    "print(\" max:   \",max(isof_scores))\n",
    "plt.plot(sorted_isof)"
   ],
   "id": "11c0b5278bd9dd84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Saling the scores from 0 to 100\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 100)) #scaling the scores from 0 to 100 using MinMaxScaler\n",
    "isof_scores = isof_scores.reshape(-1,1)\n",
    "isof_scores = scaler.fit_transform(isof_scores) #fitting the scaler\n",
    "isof_scores = 100 - isof_scores #reversing the scores\n",
    "plt.plot(isof_scores)\n",
    "#append to the dataset as a new column\n",
    "df['isof_scores'] = isof_scores\n",
    "\n"
   ],
   "id": "a79da01d810eb01b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.head()\n",
    "#save the new dataset\n",
    "df.to_csv('new_dataset.csv', index=True)\n"
   ],
   "id": "7073f34f850bfe78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6decc1ba8aa373a4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
